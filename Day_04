### ğŸ“Œ Day 4: Logistic Regression  

Welcome to Day 4 of my 100 Days of Machine Learning challenge! ğŸš€  

Todayâ€™s focus is Logistic Regression, a fundamental algorithm for classification problems. Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts categorical outcomes (e.g., Yes/No, Spam/Not Spam, 0/1).  


## ğŸ” What is Logistic Regression?
Logistic Regression is a supervised learning algorithm used for binary classification (i.e., problems with only two possible outcomes). It estimates the probability that a given input belongs to a specific category.  

ğŸ’¡ Example Use Cases: 
âœ… Email classification: Spam or Not Spam
âœ… Disease prediction: Has disease or Not  
âœ… Credit risk: Default or No Default

### ğŸ”¢ Mathematical Representation  
Instead of a straight-line equation like in Linear Regression, Logistic Regression applies the Sigmoid Function (Ïƒ) to map outputs between 0 and 1:  
where:  
- P(Y=1|X)= Probability that Y belongs to class 1  
- bâ‚€, bâ‚, ..., bâ‚™ = Model parameters (weights & bias)  
- Xâ‚, Xâ‚‚, ..., Xâ‚™ = Input features  
- e = Eulerâ€™s number (~2.718)  

If P(Y=1|X) â‰¥ 0.5, we classify it as 1; otherwise, we classify it as 0.  


## âš™ï¸ How Does It Work?**  
1ï¸âƒ£ Transform Linear Regression Output â€“ Instead of predicting continuous values, the sigmoid function squashes outputs between 0 and 1.  
2ï¸âƒ£ Threshold Decision â€“ If the probability is greater than 0.5, classify it as 1; otherwise, 0.  
3ï¸âƒ£ Optimize Model Parameters â€“ Uses techniques like Gradient Descent to minimize the Log Loss function.  


## ğŸ“ˆ Evaluating the Model  
To assess how well Logistic Regression performs, we use:  
- Accuracy â€“ Measures correct predictions.  
- Precision & Recall â€“ Helps in imbalanced datasets.  
- ROC Curve & AUC Score â€“ Measures how well the model distinguishes classes.  
