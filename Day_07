# ğŸ“Œ Day 7: Gradient Descent in Machine Learning

Welcome to Day 7 of my 100 Days of Machine Learning challenge! ğŸš€  
Todayâ€™s focus is Gradient Descent, one of the most fundamental optimization algorithms in machine learning.


## ğŸ” What is Gradient Descent?  
Gradient Descent is an optimization algorithm used to minimize the cost function by iteratively updating model parameters in the direction of the steepest descent.
ğŸ’¡ Why do we use it?  
- Helps find the best parameters (weights and biases) for a model.  
- Reduces the error of a machine learning model by minimizing the cost function.  
- Works well for large datasets and complex models.  


## ğŸ“‰ How Gradient Descent Works  
1. Compute the Gradient  
   - The gradient is the derivative of the cost function with respect to the parameters.  
   - It tells us the direction in which the cost function is increasing or decreasing.  
2. Update the Parameters  
   - Move in the opposite direction of the gradient to minimize the cost.  
   - The learning rate controls how big the steps are.  
3. Repeat Until Convergence  
   - Continue updating until the cost function stabilizes or reaches a minimum value.  


## ğŸ“Œ Gradient Descent Formula  
For a parameter Î¸ (like weight ğ‘¤ or bias ğ‘)
Î¸ = Î¸ - Î± * (âˆ‚J / âˆ‚Î¸)
where:  
- Î¸ = Model parameter (weight or bias)  
- Î± = Learning rate  
- (âˆ‚J / âˆ‚Î¸) = Derivative of cost function  
ğŸ’¡ Think of it like descending a hill â›°ï¸ â€” take small steps in the downward direction until you reach the bottom!


## ğŸ›  Types of Gradient Descent  

1ï¸âƒ£ Batch Gradient Descent 
   - Uses all training samples to compute the gradient.  
   - Slow for large datasets.  
   - More stable but computationally expensive.  
2ï¸âƒ£ Stochastic Gradient Descent (SGD)  
   - Updates parameters using one sample at a time.  
   - Faster but noisy (fluctuates a lot).  
3ï¸âƒ£ Mini-Batch Gradient Descent  
   - Uses a small batch of data (e.g., 32 or 64 samples).  
   - Balances efficiency and stability.  
   - Commonly used in deep learning.  


## ğŸ“Œ Python Implementation  

```python
import numpy as np

# Sample Data
X = np.array([1, 2, 3, 4, 5])  # Input features
y = np.array([2, 4, 6, 8, 10])  # Target values

# Initialize parameters
w = 0  # Weight
b = 0  # Bias
alpha = 0.01  # Learning rate
epochs = 1000  # Number of iterations

# Gradient Descent
for i in range(epochs):
    y_pred = w * X + b  # Predicted values
    error = y_pred - y  # Error
    
    # Compute gradients
    dw = (2/len(X)) * sum(error * X)
    db = (2/len(X)) * sum(error)
    
    # Update parameters
    w = w - alpha * dw
    b = b - alpha * db

print(f"Final Weight: {w}, Final Bias: {b}")
```

## ğŸš€ Key Takeaways  
âœ… Gradient Descent is used to minimize the cost function.  
âœ… The learning rate controls step size â€” too high â« can overshoot, too low â¬ is slow.  
âœ… Different types (Batch, Stochastic, Mini-Batch) have trade-offs in speed and stability.  

Thatâ€™s it for Day 7! Stay tuned for Day 8! ğŸš€  
