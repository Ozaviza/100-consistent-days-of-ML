### ğŸ“Œ Day 6: Cost Function in Machine Learning  

Welcome to Day 6 of my 100 Consistent Days of Machine Learning challenge! ğŸš€  
Todayâ€™s focus is Cost Function, a crucial concept that helps machine learning models evaluate how well they are performing.  


## ğŸ” What is a Cost Function?
A cost function is a mathematical function that measures the difference between the predicted output of a model and the actual output.  
ğŸ’¡ Why is it important? 
- It helps determine how well the model is performing.  
- The goal of ML models is to minimize the cost function (i.e., reduce errors).  
- Used in optimization techniques like Gradient Descent to update model parameters.  


## ğŸ“‰ Common Types of Cost Functions  

### 1ï¸âƒ£ Mean Squared Error (MSE) (for Regression Models)  
Used in linear regression and other regression-based models. 
MSE = (1/n) * Î£ (yi - Å·i)Â²
- yi = Actual value  
- Å·i = Predicted value  
- n = Number of data points  
âœ… Why use MSE? 
- Penalizes larger errors more than smaller ones.  
- Differentiable, making it useful for optimization.  
âš ï¸ Issue: Sensitive to outliers due to squaring of errors.  


### 2ï¸âƒ£ Mean Absolute Error (MAE) (for Regression Models) 
An alternative to MSE that takes the absolute difference.  
MAE = (1/n) * Î£ |yi - Å·i|
âœ… Less sensitive to outliers than MSE.  
âš ï¸ Disadvantage: Harder to optimize because it lacks a squared term.  


### 3ï¸âƒ£ Cross-Entropy Loss (for Classification Models) 
Used in classification tasks, especially logistic regression and neural networks.  
J = (-1/n) * Î£ [ yi * log(Å·i) + (1 - yi) * log(1 - Å·i) ]
âœ… Why use Cross-Entropy?  
- Works well for probability-based models (like logistic regression).  
- Helps models differentiate between correct and incorrect classifications.  
âš ï¸ Disadvantage: May cause vanishing gradients in deep networks.  


## ğŸ“ˆ Cost Function vs. Loss Function  
- Cost Function: The average loss over the entire dataset.  
- Loss Function: The error for a single data point.  
ğŸ”¹ Example: MSE is a cost function, while squared error for one sample is a loss function.  


## ğŸ›  Python Implementation    
```python
import numpy as np

# Actual and predicted values
y_actual = np.array([2, 4, 6, 8, 10])
y_predicted = np.array([2.2, 3.8, 6.1, 7.9, 9.5])

# Mean Squared Error
MSE = np.mean((y_actual - y_predicted) ** 2)

print(f"Mean Squared Error: {MSE}")
```


## ğŸš€ Key Takeaways  
âœ… The cost function measures model performance.  
âœ… The goal is to minimize the cost function to improve accuracy.  
âœ… Different types of cost functions are used for regression and classification models.  

Thatâ€™s it for Day 6! Stay tuned for Day 7! ğŸš€
