# ğŸ“Œ Day 8: Cost Function in Machine Learning  

Welcome to Day 8 of my 100 Days of Machine Learning challenge! ğŸš€  
Today, Iâ€™m diving into the Cost Function, an essential concept in training machine learning models.  


## ğŸ“– What is a Cost Function?  
A cost function measures how well a machine learning model performs by quantifying the difference between predicted values and actual values.  
ğŸ’¡ Goal: Minimize the cost function to improve the model's accuracy.  


## ğŸ“Œ Types of Cost Functions  

### 1ï¸âƒ£ Mean Squared Error (MSE) - For Regression  
The Mean Squared Error (MSE) is commonly used in regression tasks. It calculates the average squared difference between actual and predicted values.  
 MSE = (1/n) * Î£ (y_i - yÌ‚_i)^2
Where:  
- y_i = Actual value  
- yÌ‚_i = Predicted value  
- n = Number of data points  
ğŸ’¡ Why Squared?  
- Penalizes large errors more heavily.  
- Ensures the cost is always positive.  

### 2ï¸âƒ£ Mean Absolute Error (MAE) - For Regression  
Instead of squaring the errors, Mean Absolute Error (MAE) takes the absolute difference.  
MAE = (1/n) * Î£ |y_i - yÌ‚_i|
ğŸ’¡ Key Difference from MSE  
- MAE is less sensitive to large errors than MSE.  
- MSE penalizes larger errors more due to squaring.  

### 3ï¸âƒ£ Binary Cross-Entropy - For Classification  
Used in binary classification (e.g., predicting Yes/No, 0/1).  
J = -(1/n) * Î£ [ y_i * log(yÌ‚_i) + (1 - y_i) * log(1 - yÌ‚_i) ]
ğŸ’¡ Why Logarithm?  
- Logarithmic functions magnify small errors, improving model training.  

### 4ï¸âƒ£ Categorical Cross-Entropy - For Multi-Class Classification  
Used for multi-class classification problems.  
J = - Î£ Î£ y_ij * log(yÌ‚_ij)
Where:  
- k = Number of classes  
- y_ij = Actual class label (1 for correct class, 0 otherwise)  
- yÌ‚_ij = Predicted probability for class j 


## ğŸ“Œ Python Implementation of MSE 

```python
import numpy as np

# Sample Data
y_actual = np.array([2, 4, 6, 8])
y_pred = np.array([2.5, 3.8, 5.9, 7.5])

# Mean Squared Error Calculation
mse = np.mean((y_actual - y_pred) ** 2)

print(f"Mean Squared Error: {mse:.4f}")
```


## ğŸš€ Key Takeaways 
âœ… Cost functions quantify prediction errors in machine learning models.  
âœ… MSE is common in regression, while Cross-Entropy is used in classification.  
âœ… The goal of training is to minimize the cost function for better accuracy.  

Thatâ€™s it for Day 8! Stay tuned for Day 9! ğŸš€
